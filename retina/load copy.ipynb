{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  Disease_Risk\n",
      "0        1             1\n",
      "1        2             1\n",
      "2        3             1\n",
      "3        4             1\n",
      "4        5             1\n",
      "...    ...           ...\n",
      "1915  1916             1\n",
      "1916  1917             1\n",
      "1917  1918             0\n",
      "1918  1919             0\n",
      "1919  1920             0\n",
      "\n",
      "[1920 rows x 2 columns]\n",
      "ID\n",
      "Disease_Risk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "COLOR_MODE = \"grayscale\"\n",
    "CHANNELS = 1 if COLOR_MODE == \"grayscale\" else 3\n",
    "IMAGE_HEIGHT = 150\n",
    "IMAGE_WIDTH = 150\n",
    "\n",
    "TRAINING_PATH = \"./retina_dataset/Training_Set/Training_Set\"\n",
    "TRAINING_PATH_CSV = f\"{TRAINING_PATH}/RFMiD_Training_Labels.csv\"\n",
    "\n",
    "TESTING_PATH = \"./retina_dataset/Test_Set/Test_Set\"\n",
    "TESTING_PATH_CSV = f\"{TESTING_PATH}/RFMiD_Testing_Labels.csv\"\n",
    "\n",
    "VALIDATION_PATH = \"./retina_dataset/Evaluation_Set/Evaluation_Set\"\n",
    "VALIDATION_PATH_CSV = f\"{VALIDATION_PATH}/RFMiD_Validation_Labels.csv\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_PATH_CSV)\n",
    "train_df = train_df[[\"ID\",\"Disease_Risk\"]]\n",
    "\n",
    "test_df = pd.read_csv(TESTING_PATH_CSV)\n",
    "test_df = test_df[[\"ID\",\"Disease_Risk\"]]\n",
    "\n",
    "validation_df = pd.read_csv(VALIDATION_PATH_CSV)\n",
    "validation_df = validation_df[[\"ID\",\"Disease_Risk\"]]\n",
    "\n",
    "\n",
    "# print(train_df[\"Disease_Risk\"].value_counts(normalize=True))\n",
    "print(train_df)\n",
    "\n",
    "for i in train_df:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(id):\n",
    "        return f\"{id}.png\"\n",
    "\n",
    "def convert_class(label):\n",
    "        if label == 0:\n",
    "            return \"no\"\n",
    "        elif label == 1:\n",
    "            return \"yes\"\n",
    "\n",
    "train_df['name'] = train_df['ID'].apply(append_ext)\n",
    "test_df['name'] = test_df['ID'].apply(append_ext)\n",
    "validation_df['name'] = validation_df['ID'].apply(append_ext)\n",
    "\n",
    "train_df['class'] = train_df['Disease_Risk']\n",
    "test_df['class'] = test_df['Disease_Risk']\n",
    "validation_df['class'] = validation_df['Disease_Risk']\n",
    "# .apply(convert_class)\n",
    "\n",
    "train_df = train_df.drop([\"ID\", \"Disease_Risk\"], axis=1)\n",
    "test_df = test_df.drop([\"ID\", \"Disease_Risk\"], axis=1)\n",
    "validation_df = validation_df.drop([\"ID\", \"Disease_Risk\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>1916.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>1917.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>1918.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1920.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  class\n",
       "0        1.png      1\n",
       "1        2.png      1\n",
       "2        3.png      1\n",
       "3        4.png      1\n",
       "4        5.png      1\n",
       "...        ...    ...\n",
       "1915  1916.png      1\n",
       "1916  1917.png      1\n",
       "1917  1918.png      0\n",
       "1918  1919.png      0\n",
       "1919  1920.png      0\n",
       "\n",
       "[1920 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df)\n",
    "# display(test_df)\n",
    "# display(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def get_images_labels(image_folder_path, dataframe):\n",
    "    # Load and preprocess images\n",
    "\timages = []\n",
    "\tlabels = []\n",
    "\n",
    "\tfor index, row in dataframe.iterrows():\n",
    "\t\timage_path = os.path.join(image_folder_path, row['name'])\n",
    "\t\timage = load_img(\n",
    "\t\t\timage_path,\n",
    "\t\t\tcolor_mode=COLOR_MODE,\n",
    "\t\t\ttarget_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "\t\t\tinterpolation='nearest',\n",
    "\t\t)  # Assuming images are resized to 128x128 pixels\n",
    "\t\timage = img_to_array(image) / 255.0  # Rescale pixel values to [0, 1]\n",
    "\t\timages.append(image)\n",
    "\t\tlabels.append(row['class'])\n",
    "\n",
    "\t# Convert lists to NumPy arrays\n",
    "\timages = np.array(images)\n",
    "\tlabels = np.array(labels)\n",
    "\n",
    "\treturn images, labels\n",
    "\n",
    "train_ds_images, train_ds_labels = get_images_labels(f\"{TRAINING_PATH}/Training\", train_df)\n",
    "test_ds_images, test_ds_labels = get_images_labels(f\"{TESTING_PATH}/Test\", test_df)\n",
    "validation_ds_images, validation_ds_labels = get_images_labels(f\"{VALIDATION_PATH}/Validation\", validation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into training and testing sets\n",
    "# x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of augmented dataset: (9600, 150, 150)\n",
      "Shape of augmented labels: (9600,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def random_flip(image):\n",
    "    # Random horizontal and vertical flip\n",
    "    if np.random.rand() < 0.5:  # 50% probability for each flip\n",
    "        image = np.flip(image, axis=0)  # Vertical flip\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = np.flip(image, axis=1)  # Horizontal flip\n",
    "    return image\n",
    "\n",
    "def random_rotation(image):\n",
    "    # Random rotation within the range [-1, 1] degree\n",
    "    angle = np.random.uniform(-1, 1)\n",
    "    rows, cols, _ = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    rotated_image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    return rotated_image\n",
    "\n",
    "def random_translation(image, max_translation_x, max_translation_y):\n",
    "    # Check if the image is grayscale\n",
    "    if len(image.shape) == 2:\n",
    "        # Reshape the grayscale image to add the third dimension\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "    # Random translation by up to max_translation_x and max_translation_y\n",
    "    rows, cols, channels = image.shape\n",
    "    tx = np.random.uniform(-max_translation_x, max_translation_x) * cols\n",
    "    ty = np.random.uniform(-max_translation_y, max_translation_y) * rows\n",
    "    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    translated_image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    return translated_image\n",
    "\n",
    "def random_zoom(image, min_zoom, max_zoom):\n",
    "    # Random zoom within the range [min_zoom, max_zoom]\n",
    "    zoom_factor = np.random.uniform(min_zoom, max_zoom)\n",
    "    if len(image.shape) == 2:  # Grayscale image\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "    rows, cols, channels = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 0, zoom_factor)\n",
    "    zoomed_image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    return zoomed_image\n",
    "\n",
    "def random_brightness(image, max_delta):\n",
    "    # Random brightness adjustment within the range [-max_delta, max_delta]\n",
    "    delta = np.random.uniform(-max_delta, max_delta)\n",
    "    adjusted_image = np.clip(image + delta, 0, 255)\n",
    "    return adjusted_image\n",
    "\n",
    "def random_contrast(image, lower, upper):\n",
    "    # Random contrast adjustment within the range [lower, upper]\n",
    "    alpha = np.random.uniform(lower, upper)\n",
    "    adjusted_image = np.clip(alpha * image, 0, 255)\n",
    "    return adjusted_image\n",
    "\n",
    "# # Example usage\n",
    "# image = np.random.rand(128, 128, 3) * 255  # Example image of size 128x128x3 (RGB)\n",
    "\n",
    "# # Apply random transformations\n",
    "# image = random_flip(image)\n",
    "# image = random_rotation(image)\n",
    "# image = random_translation(image, max_translation_x=0.2, max_translation_y=0.2)\n",
    "# image = random_zoom(image, min_zoom=0.8, max_zoom=1.2)\n",
    "# image = random_brightness(image, max_delta=0.2)\n",
    "# image = random_contrast(image, lower=0.8, upper=1.2)\n",
    "\n",
    "\n",
    "original_images = train_ds_images\n",
    "original_labels = train_ds_labels\n",
    "\n",
    "def apply_augmentations(image):\n",
    "    max_translation_x = 0.2\n",
    "    max_translation_y=0.2\n",
    "    min_zoom=0.8\n",
    "    max_zoom=1.2\n",
    "    max_brightness_delta=0.2\n",
    "    min_contrast=0.8\n",
    "    max_contrast=1.2\n",
    "     \n",
    "    augmented_image = image.copy()  # Make a copy of the original image\n",
    "    # Apply random transformations to the image\n",
    "    augmented_image = random_flip(augmented_image)\n",
    "    augmented_image = random_rotation(augmented_image)\n",
    "    augmented_image = random_translation(augmented_image, max_translation_x, max_translation_y)\n",
    "    augmented_image = random_zoom(augmented_image, min_zoom, max_zoom)\n",
    "    augmented_image = random_brightness(augmented_image, max_brightness_delta)\n",
    "    augmented_image = random_contrast(augmented_image, min_contrast, max_contrast)\n",
    "    return augmented_image\n",
    "\n",
    "# Define the desired number of augmented images per original image\n",
    "num_augmented_per_image = 5  # Adjust as needed\n",
    "# Initialize lists to store augmented images and their corresponding labels\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "# Apply augmentations to each original image\n",
    "for _ in range(num_augmented_per_image):\n",
    "    for i, image in enumerate(original_images):\n",
    "        # Apply data augmentation techniques to the image\n",
    "        augmented_image = apply_augmentations(image)\n",
    "        augmented_images.append(augmented_image)\n",
    "        # Repeat the corresponding label for the augmented images\n",
    "        augmented_labels.append(original_labels[i])\n",
    "        \n",
    "# Convert the lists of augmented images and labels to NumPy arrays\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "# Verify the shapes of the augmented dataset and labels\n",
    "print(\"Shape of augmented dataset:\", augmented_images.shape)\n",
    "print(\"Shape of augmented labels:\", augmented_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 37, 37, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 37, 37, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 18, 18, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 9, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20736)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20736)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              21234688  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,893,185\n",
      "Trainable params: 21,893,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# # Define the CNN model\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)),\n",
    "\n",
    "    # preprocessing,\n",
    "\n",
    "    # keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\",input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "\n",
    "    # keras.layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"), #sigmoid is for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(), \n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary(\n",
    "    expand_nested=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600 9600\n",
      "640 640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9600, 150, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(train_ds_images), len(train_ds_labels))\n",
    "# print(len(validation_ds_images), len(validation_ds_labels))\n",
    "print(len(augmented_images), len(augmented_labels))\n",
    "print(len(validation_ds_images), len(validation_ds_labels))\n",
    "augmented_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 23s 114ms/step - loss: 0.5090 - binary_accuracy: 0.7906 - val_loss: 0.5080 - val_binary_accuracy: 0.7906\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.4994 - binary_accuracy: 0.7911 - val_loss: 0.5349 - val_binary_accuracy: 0.7906\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4976 - binary_accuracy: 0.7911 - val_loss: 0.4987 - val_binary_accuracy: 0.7906\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4936 - binary_accuracy: 0.7911 - val_loss: 0.4994 - val_binary_accuracy: 0.7906\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4920 - binary_accuracy: 0.7911 - val_loss: 0.5223 - val_binary_accuracy: 0.7906\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.4867 - binary_accuracy: 0.7911 - val_loss: 0.5119 - val_binary_accuracy: 0.7906\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.4809 - binary_accuracy: 0.7909 - val_loss: 0.5116 - val_binary_accuracy: 0.7906\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4698 - binary_accuracy: 0.7922 - val_loss: 0.4870 - val_binary_accuracy: 0.7922\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4560 - binary_accuracy: 0.7987 - val_loss: 0.4637 - val_binary_accuracy: 0.7781\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4375 - binary_accuracy: 0.8011 - val_loss: 0.5041 - val_binary_accuracy: 0.7953\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.4173 - binary_accuracy: 0.8154 - val_loss: 0.4903 - val_binary_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.3930 - binary_accuracy: 0.8272 - val_loss: 0.6486 - val_binary_accuracy: 0.5859\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.3630 - binary_accuracy: 0.8374 - val_loss: 0.4856 - val_binary_accuracy: 0.7594\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.3226 - binary_accuracy: 0.8534 - val_loss: 0.4677 - val_binary_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.2867 - binary_accuracy: 0.8796 - val_loss: 0.4908 - val_binary_accuracy: 0.7719\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.2415 - binary_accuracy: 0.9003 - val_loss: 0.8024 - val_binary_accuracy: 0.7984\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.1933 - binary_accuracy: 0.9218 - val_loss: 0.7955 - val_binary_accuracy: 0.6875\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.1569 - binary_accuracy: 0.9393 - val_loss: 0.9136 - val_binary_accuracy: 0.6797\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.1265 - binary_accuracy: 0.9521 - val_loss: 0.8767 - val_binary_accuracy: 0.7609\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.1030 - binary_accuracy: 0.9590 - val_loss: 0.8244 - val_binary_accuracy: 0.7750\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.0674 - binary_accuracy: 0.9757 - val_loss: 1.1372 - val_binary_accuracy: 0.7281\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.0652 - binary_accuracy: 0.9766 - val_loss: 1.2923 - val_binary_accuracy: 0.6906\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.0517 - binary_accuracy: 0.9829 - val_loss: 0.8081 - val_binary_accuracy: 0.7781\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.0493 - binary_accuracy: 0.9833 - val_loss: 1.1950 - val_binary_accuracy: 0.7188\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 17s 112ms/step - loss: 0.0343 - binary_accuracy: 0.9898 - val_loss: 1.2237 - val_binary_accuracy: 0.7656\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 17s 113ms/step - loss: 0.0383 - binary_accuracy: 0.9867 - val_loss: 1.3812 - val_binary_accuracy: 0.6703\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 0.0350 - binary_accuracy: 0.9885 - val_loss: 0.9046 - val_binary_accuracy: 0.7781\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 17s 112ms/step - loss: 0.0303 - binary_accuracy: 0.9904 - val_loss: 1.1007 - val_binary_accuracy: 0.7266\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.0237 - binary_accuracy: 0.9927 - val_loss: 1.8277 - val_binary_accuracy: 0.6484\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.0242 - binary_accuracy: 0.9923 - val_loss: 1.0201 - val_binary_accuracy: 0.7688\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 0.0282 - binary_accuracy: 0.9914 - val_loss: 1.1541 - val_binary_accuracy: 0.7672\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 17s 114ms/step - loss: 0.0230 - binary_accuracy: 0.9917 - val_loss: 1.0982 - val_binary_accuracy: 0.7484\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 17s 114ms/step - loss: 0.0362 - binary_accuracy: 0.9880 - val_loss: 1.1953 - val_binary_accuracy: 0.7766\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 17s 114ms/step - loss: 0.0235 - binary_accuracy: 0.9930 - val_loss: 1.1437 - val_binary_accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "# # Train the model\n",
    "EPOCHS = 100\n",
    "PATIENCE = 25\n",
    "BATCH_SIZE = 64\n",
    "earlystop_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = augmented_images,\n",
    "    y = augmented_labels,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(validation_ds_images, validation_ds_labels),\n",
    "    callbacks=[earlystop_loss],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 18ms/step - loss: 0.4083 - binary_accuracy: 0.8047\n",
      "Test Accuracy: 0.8046875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_ds_images, test_ds_labels)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
