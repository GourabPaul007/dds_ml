{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Dataset/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sex'].value_counts())\n",
    "print(df['chest_pain_type'].value_counts())\n",
    "print(df['resting_ecg'].value_counts())\n",
    "print(df['exercise_angina'].value_counts())\n",
    "print(df['st_slope'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Category and sex are two categorical objects needed to convert to numerical data.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['sex']= le.fit_transform(df['sex'])\n",
    "df['chest_pain_type']= le.fit_transform(df['chest_pain_type'])\n",
    "df['resting_ecg']= le.fit_transform(df['resting_ecg'])\n",
    "df['exercise_angina']= le.fit_transform(df['exercise_angina'])\n",
    "df['st_slope']= le.fit_transform(df['st_slope'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['heart_disease'], axis=1)\n",
    "y = df['heart_disease']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=80)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print('Train acc -> ',gbc.score(X_train,y_train)*100)\n",
    "print('Test acc -> ',gbc.score(X_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# # Define the parameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "# }\n",
    " \n",
    "# gb_model = GradientBoostingClassifier()\n",
    " \n",
    "# grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    " \n",
    "# grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_abc = gbc.predict(X_test)\n",
    "print(y_pred_abc)\n",
    "from sklearn.metrics import confusion_matrix, classification_report,mean_absolute_error,mean_squared_error\n",
    "cm_gbc = confusion_matrix(y_test, y_pred_abc)\n",
    "cm_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm_gbc, annot=True)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "\n",
    "print(classification_report(y_test, y_pred_abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE MODEL USING PICKLE PACKAGE\n",
    "import pickle\n",
    "\n",
    "# save the iris classification model as a pickle file\n",
    "model_pkl_file = \"./hd-gbc.pkl\"\n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(gbc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model \n",
    "# LOAD AND USE THE SAVED MODEL USING PICKLE PACKAGE\n",
    "with open(model_pkl_file, 'rb') as file:  \n",
    "    loaded_rf = pickle.load(file)\n",
    "    y_pred = loaded_rf.predict(X_test)\n",
    "\n",
    "    # check results\n",
    "    pred = loaded_rf.score(X_test, y_test)\n",
    "    print(f\"Accuracy : {pred * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
