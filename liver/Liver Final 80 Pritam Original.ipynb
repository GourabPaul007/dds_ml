{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "130610a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Mean Accuracy: 0.7715131578947367\n",
      "Validation Accuracy: 0.7610062893081762\n",
      "Test Accuracy: 0.81875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Current BestFit\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "Liver_df = pd.read_csv('ILPD_Set.csv')\n",
    "Liver_df['Selector'] = Liver_df['Selector'] - 1\n",
    "\n",
    "# Liver_df = pd.concat([Liver_df] * 4, ignore_index=True)\n",
    "\n",
    "# Step 2: Fill missing values in 'A/G Ratio' based on correlation with 'ALB'\n",
    "def fill_agr_missing(row):\n",
    "    if pd.isnull(row['A/G Ratio']):\n",
    "        return row['ALB'] * correlation\n",
    "    return row['A/G Ratio']\n",
    "\n",
    "non_null_df = Liver_df.dropna(subset=['ALB', 'A/G Ratio'])\n",
    "correlation = non_null_df['ALB'].corr(non_null_df['A/G Ratio'])\n",
    "Liver_df['A/G Ratio'] = Liver_df.apply(fill_agr_missing, axis=1)\n",
    "\n",
    "# Step 3: Encode gender to numeric values\n",
    "Liver_df[\"Gender\"] = Liver_df[\"Gender\"].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Step 4: Identify and remove outliers using the IQR method\n",
    "Q1 = Liver_df.quantile(0.10)\n",
    "Q3 = Liver_df.quantile(0.90)\n",
    "IQR = Q3 - Q1\n",
    "outlier_step = 1.5\n",
    "outliers = ((Liver_df < (Q1 - outlier_step * IQR)) | (Liver_df > (Q3 + outlier_step * IQR))).DB\n",
    "df_clean = Liver_df[~outliers]\n",
    "\n",
    "# Step 5: Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df_clean), columns=df_clean.columns)\n",
    "\n",
    "# Step 6: Split features and target variable\n",
    "Liver_df_expanded = df_filled.drop([\"DB\"], axis=1)\n",
    "Liver_df_expanded.rename(columns={'Selector': 'Outcome'}, inplace=True)\n",
    "y = Liver_df_expanded['Outcome'].copy()\n",
    "X = Liver_df_expanded.drop('Outcome', axis=1)\n",
    "\n",
    "# Step 7: Normalization/Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 8 Balance classes using SMOTE\n",
    "X_balanced, y_balanced = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Split the data into training, validation, and test sets (60% train, 20% validation, 20% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_balanced, y_balanced, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the Random Forest model within a pipeline with StandardScaler and RandomForestClassifier\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42))\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Train the model on the entire training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "# Validation accuracy\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Validation Accuracy:\", accuracy_val)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Test accuracy\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306e0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c349d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Parameters: {'model__max_depth': 20, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 50}\n",
      "Random Forest Validation Accuracy: 0.7672955974842768\n",
      "Random Forest Test Accuracy: 0.7625\n",
      "Gradient Boosting Best Parameters: {'model__learning_rate': 0.5, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "Gradient Boosting Validation Accuracy: 0.8176100628930818\n",
      "Gradient Boosting Test Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "Liver_df = pd.read_csv('ILPD_Set.csv')\n",
    "Liver_df['Selector'] = Liver_df['Selector'] - 1\n",
    "\n",
    "# Step 2: Fill missing values in 'A/G Ratio' based on correlation with 'ALB'\n",
    "def fill_agr_missing(row):\n",
    "    if pd.isnull(row['A/G Ratio']):\n",
    "        return row['ALB'] * correlation\n",
    "    return row['A/G Ratio']\n",
    "\n",
    "non_null_df = Liver_df.dropna(subset=['ALB', 'A/G Ratio'])\n",
    "correlation = non_null_df['ALB'].corr(non_null_df['A/G Ratio'])\n",
    "Liver_df['A/G Ratio'] = Liver_df.apply(fill_agr_missing, axis=1)\n",
    "\n",
    "# Step 3: Encode gender to numeric values\n",
    "Liver_df[\"Gender\"] = Liver_df[\"Gender\"].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Step 4: Identify and remove outliers using the IQR method\n",
    "Q1 = Liver_df.quantile(0.10)\n",
    "Q3 = Liver_df.quantile(0.90)\n",
    "IQR = Q3 - Q1\n",
    "outlier_step = 1.5\n",
    "outliers = ((Liver_df < (Q1 - outlier_step * IQR)) | (Liver_df > (Q3 + outlier_step * IQR))).DB\n",
    "df_clean = Liver_df[~outliers]\n",
    "\n",
    "# Step 5: Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df_clean), columns=df_clean.columns)\n",
    "\n",
    "# Step 6: Split features and target variable\n",
    "Liver_df_expanded = df_filled.drop([\"DB\"], axis=1)\n",
    "Liver_df_expanded.rename(columns={'Selector': 'Outcome'}, inplace=True)\n",
    "y = Liver_df_expanded['Outcome'].copy()\n",
    "X = Liver_df_expanded.drop('Outcome', axis=1)\n",
    "\n",
    "# Step 7: Normalization/Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 8 Balance classes using SMOTE\n",
    "X_balanced, y_balanced = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Split the data into training, validation, and test sets (60% train, 20% validation, 20% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_balanced, y_balanced, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define models with hyperparameter grids\n",
    "models = {\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [10, 20, 30],\n",
    "            \"model__min_samples_leaf\": [1, 2, 4],\n",
    "            \"model__min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [3, 5, 7],\n",
    "            \"model__min_samples_split\": [2, 5, 10],\n",
    "            \"model__min_samples_leaf\": [1, 2, 4],\n",
    "            \"model__learning_rate\": [0.01, 0.1, 0.5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate each model with hyperparameter tuning\n",
    "for name, model_info in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model_info[\"model\"])\n",
    "    ])\n",
    "    clf = GridSearchCV(pipeline, model_info[\"params\"], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(f\"{name} Best Parameters:\", clf.best_params_)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    print(f\"{name} Validation Accuracy:\", accuracy_val)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"{name} Test Accuracy:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cc6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "24c9716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8113207547169812\n",
      "Test Accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "Liver_df = pd.read_csv('ILPD_Set.csv')\n",
    "Liver_df['Selector'] = Liver_df['Selector'] - 1\n",
    "\n",
    "# Step 2: Fill missing values in 'A/G Ratio' based on correlation with 'ALB'\n",
    "def fill_agr_missing(row):\n",
    "    if pd.isnull(row['A/G Ratio']):\n",
    "        return row['ALB'] * correlation\n",
    "    return row['A/G Ratio']\n",
    "\n",
    "non_null_df = Liver_df.dropna(subset=['ALB', 'A/G Ratio'])\n",
    "correlation = non_null_df['ALB'].corr(non_null_df['A/G Ratio'])\n",
    "Liver_df['A/G Ratio'] = Liver_df.apply(fill_agr_missing, axis=1)\n",
    "\n",
    "# Step 3: Encode gender to numeric values\n",
    "Liver_df[\"Gender\"] = Liver_df[\"Gender\"].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Step 4: Identify and remove outliers using the IQR method\n",
    "Q1 = Liver_df.quantile(0.10)\n",
    "Q3 = Liver_df.quantile(0.90)\n",
    "IQR = Q3 - Q1\n",
    "outlier_step = 1.5\n",
    "outliers = ((Liver_df < (Q1 - outlier_step * IQR)) | (Liver_df > (Q3 + outlier_step * IQR))).DB\n",
    "df_clean = Liver_df[~outliers]\n",
    "\n",
    "# Step 5: Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df_clean), columns=df_clean.columns)\n",
    "\n",
    "# Step 6: Split features and target variable\n",
    "Liver_df_expanded = df_filled.drop([\"DB\"], axis=1)\n",
    "Liver_df_expanded.rename(columns={'Selector': 'Outcome'}, inplace=True)\n",
    "y = Liver_df_expanded['Outcome'].copy()\n",
    "X = Liver_df_expanded.drop('Outcome', axis=1)\n",
    "\n",
    "# Step 7: Normalization/Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 8 Balance classes using SMOTE\n",
    "X_balanced, y_balanced = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Split the data into training, validation, and test sets (60% train, 20% validation, 20% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_balanced, y_balanced, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define Gradient Boosting model with specified hyperparameters\n",
    "model = GradientBoostingClassifier(learning_rate=0.5, max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100, random_state=42)\n",
    "\n",
    "# Build the model within a pipeline with StandardScaler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "\n",
    "# Validation accuracy\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Validation Accuracy:\", accuracy_val)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Test accuracy\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664fc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3265a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
