{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130610a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                           0\n",
       "gender                        0\n",
       "total_bilirubin               0\n",
       "direct_bilirubin              0\n",
       "alkaline_phosphotase          0\n",
       "alamine_aminotransferase      0\n",
       "aspartate_aminotransferase    0\n",
       "total_protiens                0\n",
       "albumin                       0\n",
       "albumin_and_globulin_ratio    4\n",
       "dataset                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "Liver_df = pd.read_csv('indian_liver_patient.csv', skipinitialspace=True) #skipinitialspace for the gender column\n",
    "# Liver_df['Selector'] = Liver_df['Selector'] - 1\n",
    "\n",
    "# Liver_df = pd.concat([Liver_df] * 4, ignore_index=True)\n",
    "Liver_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60250c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Fill missing values in 'A/G Ratio' based on correlation with 'ALB'\n",
    "# def fill_agr_missing(row):\n",
    "#     if pd.isnull(row['albumin_and_globulin_ratio']):\n",
    "#         return row['albumin'] * correlation\n",
    "#     return row['albumin_and_globulin_ratio']\n",
    "\n",
    "# non_null_df = Liver_df.dropna(subset=['albumin', 'albumin_and_globulin_ratio'])\n",
    "# correlation = non_null_df['albumin'].corr(non_null_df['albumin_and_globulin_ratio'])\n",
    "# Liver_df['albumin_and_globulin_ratio'] = Liver_df.apply(fill_agr_missing, axis=1)\n",
    "Liver_df.dropna(subset=['albumin_and_globulin_ratio'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c5c37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>total_bilirubin</th>\n",
       "      <th>direct_bilirubin</th>\n",
       "      <th>alkaline_phosphotase</th>\n",
       "      <th>alamine_aminotransferase</th>\n",
       "      <th>aspartate_aminotransferase</th>\n",
       "      <th>total_protiens</th>\n",
       "      <th>albumin</th>\n",
       "      <th>albumin_and_globulin_ratio</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  total_bilirubin  direct_bilirubin  alkaline_phosphotase  \\\n",
       "0     65       1              0.7               0.1                   187   \n",
       "1     62       0             10.9               5.5                   699   \n",
       "2     62       0              7.3               4.1                   490   \n",
       "3     58       0              1.0               0.4                   182   \n",
       "4     72       0              3.9               2.0                   195   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "578   60       0              0.5               0.1                   500   \n",
       "579   40       0              0.6               0.1                    98   \n",
       "580   52       0              0.8               0.2                   245   \n",
       "581   31       0              1.3               0.5                   184   \n",
       "582   38       0              1.0               0.3                   216   \n",
       "\n",
       "     alamine_aminotransferase  aspartate_aminotransferase  total_protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     albumin  albumin_and_globulin_ratio  dataset  \n",
       "0        3.3                        0.90        1  \n",
       "1        3.2                        0.74        1  \n",
       "2        3.3                        0.89        1  \n",
       "3        3.4                        1.00        1  \n",
       "4        2.4                        0.40        1  \n",
       "..       ...                         ...      ...  \n",
       "578      1.6                        0.37        2  \n",
       "579      3.2                        1.10        1  \n",
       "580      3.2                        1.00        1  \n",
       "581      3.4                        1.00        1  \n",
       "582      4.4                        1.50        2  \n",
       "\n",
       "[579 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 3: Encode gender to numeric values\n",
    "Liver_df[\"gender\"] = Liver_df[\"gender\"].map({'Male': 0, 'Female': 1})\n",
    "Liver_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0bbbc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>total_bilirubin</th>\n",
       "      <th>direct_bilirubin</th>\n",
       "      <th>alkaline_phosphotase</th>\n",
       "      <th>alamine_aminotransferase</th>\n",
       "      <th>aspartate_aminotransferase</th>\n",
       "      <th>total_protiens</th>\n",
       "      <th>albumin</th>\n",
       "      <th>albumin_and_globulin_ratio</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  total_bilirubin  direct_bilirubin  alkaline_phosphotase  \\\n",
       "0     65       1              0.7               0.1                   187   \n",
       "1     62       0             10.9               5.5                   699   \n",
       "2     62       0              7.3               4.1                   490   \n",
       "3     58       0              1.0               0.4                   182   \n",
       "4     72       0              3.9               2.0                   195   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "578   60       0              0.5               0.1                   500   \n",
       "579   40       0              0.6               0.1                    98   \n",
       "580   52       0              0.8               0.2                   245   \n",
       "581   31       0              1.3               0.5                   184   \n",
       "582   38       0              1.0               0.3                   216   \n",
       "\n",
       "     alamine_aminotransferase  aspartate_aminotransferase  total_protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     albumin  albumin_and_globulin_ratio  dataset  \n",
       "0        3.3                        0.90        1  \n",
       "1        3.2                        0.74        1  \n",
       "2        3.3                        0.89        1  \n",
       "3        3.4                        1.00        1  \n",
       "4        2.4                        0.40        1  \n",
       "..       ...                         ...      ...  \n",
       "578      1.6                        0.37        2  \n",
       "579      3.2                        1.10        1  \n",
       "580      3.2                        1.00        1  \n",
       "581      3.4                        1.00        1  \n",
       "582      4.4                        1.50        2  \n",
       "\n",
       "[522 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Identify and remove outliers using the IQR method\n",
    "Indexes = []\n",
    "\n",
    "for col in Liver_df.columns:\n",
    "    q1 = Liver_df[col].quantile(0.10)\n",
    "    q3 = Liver_df[col].quantile(0.90)\n",
    "    iqr = q1 - q3\n",
    "    outlier_step = 1.5\n",
    "    lowerLimit, upperLimit = q1+outlier_step*iqr, q3-outlier_step*iqr\n",
    "\n",
    "    outliers = Liver_df.loc[(Liver_df[col]<lowerLimit) | (Liver_df[col]>upperLimit)].index\n",
    "\n",
    "    for ele in outliers:\n",
    "        if ele not in Indexes:\n",
    "            Indexes.append(ele)\n",
    "\n",
    "df_clean = Liver_df.drop(index=Indexes)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11162627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df_clean), columns=df_clean.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a127f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Split features and target variable\n",
    "# Liver_df_expanded = df_filled.drop([\"DB\"], axis=1)\n",
    "# Liver_df_expanded.rename(columns={'Selector': 'Outcome'}, inplace=True)\n",
    "# y = Liver_df_expanded['Outcome'].copy()\n",
    "# X = Liver_df_expanded.drop('Outcome', axis=1)\n",
    "y = Liver_df['dataset'].copy()\n",
    "X = Liver_df.drop('dataset', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84abf5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Normalization/Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 8 Balance classes using SMOTE\n",
    "X_balanced, y_balanced = SMOTE().fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e311649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Mean Accuracy: 0.7991341991341991\n",
      "Test Accuracy: 0.8313253012048193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split the data into training, validation, and test sets (60% train, 20% validation, 20% test)\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X_balanced, y_balanced, test_size=0.4, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Random Forest model within a pipeline with StandardScaler and RandomForestClassifier\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42))\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Train the model on the entire training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "# print(\"Validation Accuracy:\", accuracy_val)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c349d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Parameters: {'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 50}\n",
      "Random Forest Test Accuracy: 0.8072289156626506\n",
      "Gradient Boosting Best Parameters: {'model__learning_rate': 0.5, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}\n",
      "Gradient Boosting Test Accuracy: 0.8373493975903614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Define models with hyperparameter grids\n",
    "models = {\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [10, 20, 30],\n",
    "            \"model__min_samples_leaf\": [1, 2, 4],\n",
    "            \"model__min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [3, 5, 7],\n",
    "            \"model__min_samples_split\": [2, 5, 10],\n",
    "            \"model__min_samples_leaf\": [1, 2, 4],\n",
    "            \"model__learning_rate\": [0.01, 0.1, 0.5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate each model with hyperparameter tuning\n",
    "for name, model_info in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model_info[\"model\"])\n",
    "    ])\n",
    "    clf = GridSearchCV(pipeline, model_info[\"params\"], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(f\"{name} Best Parameters:\", clf.best_params_)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    # y_pred_val = clf.predict(X_val)\n",
    "    # accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    # print(f\"{name} Validation Accuracy:\", accuracy_val)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Test Accuracy:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cc6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c9716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8192771084337349\n"
     ]
    }
   ],
   "source": [
    "# Define Gradient Boosting model with specified hyperparameters\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# model = GradientBoostingClassifier(learning_rate=0.5, max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100, random_state=42)\n",
    "model = GradientBoostingClassifier(learning_rate=0.5, max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50, random_state=42)\n",
    "\n",
    "# Build the model within a pipeline with StandardScaler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "# y_pred_val = pipeline.predict(X_val)\n",
    "# accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "# print(\"Validation Accuracy:\", accuracy_val)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8664fc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth Values')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Truth Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3265a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE MODEL USING PICKLE PACKAGE\n",
    "\n",
    "import pickle\n",
    "\n",
    "# save the iris classification model as a pickle file\n",
    "model_pkl_file = \"./liver-gbc.pkl\"\n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
